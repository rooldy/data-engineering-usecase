## √âtape 3 ‚Äî Architecture Technique Cible

### üéØ Objectif de l‚Äô√©tape
D√©crire pr√©cis√©ment **l‚Äôarchitecture technique** de ton use case data engineering : les composants utilis√©s, les flux entre chaque couche, et la logique globale du pipeline (Ingestion ‚Üí Stockage ‚Üí Traitement ‚Üí Transformation ‚Üí Restitution).

---

## üèóÔ∏è Architecture Technique Cible

### 1. **Sources de donn√©es**
- **ERP pharmaceutique** (donn√©es transactionnelles : ventes, stocks, livraisons)
- **Syst√®me de capteurs IoT** (consommation √©nerg√©tique, mesure en temps r√©el)
- **Fichiers CSV / JSON** d√©pos√©s dans un bucket S3 ou un dossier partag√©
- **Base PostgreSQL** interne (r√©f√©rentiels, produits, entit√©s)
- **API externes** pour r√©cup√©rer des mises √† jour r√©glementaires

---

### 2. **Ingestion des donn√©es**
- **AWS S3** comme point d‚Äôatterrissage (_landing zone_)
- **AWS Glue Jobs / Python / PySpark**
  - ingestion batch depuis S3
  - ingestion JDBC depuis PostgreSQL
  - ingestion streaming depuis capteurs IoT via Amazon Kinesis
- **Airflow** pour orchestrer les DAG :
  - `dag_ingest_erp`
  - `dag_ingest_iot`
  - `dag_ingest_ref_data`

---

### 3. **Zone de stockage (Data Lake)**
Organisation en 3 zones standard :
- **Bronze** : donn√©es brutes (raw)
- **Silver** : donn√©es nettoy√©es et structur√©es
- **Gold** : donn√©es business pr√™tes pour l‚Äôanalyse et la BI

Stockage principal :
- **S3 Data Lake** avec partitionnement :
  - `/bronze/source=erp/year=2025/month=12/day=01/`
  - `/silver/domain=pharma/table=ventes/`
  - `/gold/domain=energy/model=prediction/`

Format utilis√© :
- **Parquet** (optimis√© pour lecture analytique)
- **Delta Lake** (si need versioning & ACID)

---

### 4. **Traitement et Transformation**
- **AWS Glue / PySpark / Spark Scala**
  - nettoyages (schemas, types, formats)
  - jointures entre r√©f√©rentiels (produits, zones, machines)
  - enrichissement par les donn√©es de capteurs
  - d√©tection d‚Äôanomalies (outliers)
  - calcul des KPI m√©tiers
- **Snowflake** (si inclusion pr√©vue) :
  - loading via Snowpipe
  - transformation SQL (ELT)
  - cr√©ation de vues m√©tiers

---

### 5. **Mod√©lisation**
- **Mod√®le en √©toile** (_Star Schema_) :
  - Tables de faits :
    - `fact_ventes`
    - `fact_consommation_energie`
    - `fact_production`
  - Tables de dimensions :
    - `dim_produit`
    - `dim_machine`
    - `dim_temps`
    - `dim_site`
- Business rules appliqu√©es :
  - calcul des marges
  - classification des anomalies
  - normalisation √©nerg√©tique par production

---

### 6. **Orchestration & automatisation**
- **Apache Airflow**
  - planification quotidienne
  - gestion des d√©pendances
  - int√©gration GitHub + CI/CD
  - alertes sur erreur
- Pipelines typiques :
  - `pipeline_ingestion`
  - `pipeline_transformation`
  - `pipeline_qualite`
  - `pipeline_load_bi`

---

### 7. **Restitution & Analyse**
- **Power BI / Tableau**
  - tableaux de bord pharmaceutiques :
    - taux de rupture
    - performance logistique
  - dashboards √©nergie :
    - consommation en temps r√©el
    - anomalies machines
- Exposition des donn√©es via :
  - API internes
  - Vues Snowflake / Postgres pour la BI

---

### 8. **S√©curit√© & Gouvernance**
- **IAM Fine-grained access**
- **Chiffrement S3 KMS**
- **Gestion des logs CloudTrail**
- **Data quality : Great Expectations**
- **Catalogage & metadonn√©es : AWS Glue Catalog**
- **Conformit√© : GDPR + normes pharmaceutiques**

---

### üî• R√©sultat attendu
Une architecture compl√®te, scalable et s√©curis√©e permettant :
- d‚Äôing√©rer plusieurs types de donn√©es
- de les transformer en tables analytiques
- de produire un reporting fiable
- de supporter un cas d‚Äôusage pharmaceutique + √©nergie

